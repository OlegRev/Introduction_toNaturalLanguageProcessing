{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c5714a0",
   "metadata": {},
   "source": [
    "# Тема “Сверточные нейронные сети для анализа текста”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4feab413",
   "metadata": {},
   "source": [
    "Задания:\n",
    "<ol>\n",
    "<li><a href=\"#task_1\">Учим conv сеть для классификации</a>  \n",
    "<li><a href = \"#task_2\">Рассмотреть 2-а варианта сеточек</a>\n",
    "<ol><li type=\"1\"><a href = \"#task_2.1\">Инициализировать tf.keras.layers.Embedding предобученными векторами взять к примеру с https://rusvectores.org/ru/</a>\n",
    "    <li type=\"1\"><a href=\"#task_2.2\">Инициализировать слой tf.keras.layers.Embedding по умолчанию (ну то есть вам ничего не делать с весами)</a></ol>\n",
    "<li ><a href=\"#task_3\">Сравнить две архитектуры с предобученными весами и когда tf.keras.layers.Embedding обучается сразу со всей сеточкой, что получилось лучше</a>\n",
    "\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4e3e99",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44f1a039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow\n",
    "\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Input, Embedding, Conv1D, GlobalMaxPool1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import TensorBoard \n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.callbacks import EarlyStopping  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250049e2",
   "metadata": {},
   "source": [
    "## Загрузка и предобработка данных\n",
    "> ### Берем отызывы за лето (из архива с материалами или предыдущего занятия)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab675519-edf4-4c8b-ba54-06ea79da97d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c39a34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:\n",
      "(20659, 3)\n",
      "Describe:\n",
      "          count      mean       std  min  25%  50%  75%  max\n",
      "Rating  20659.0  4.259015  1.348884  1.0  4.0  5.0  5.0  5.0\n",
      "Column name:\n",
      "Index(['Rating', 'Content', 'Date'], dtype='object')\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Content</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>It just works!</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>В целом удобноное приложение...из минусов хотя...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Отлично все</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Стал зависать на 1% работы антивируса. Дальше ...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Очень удобно, работает быстро.</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating                                            Content        Date\n",
       "0       5                                     It just works!  2017-08-14\n",
       "1       4  В целом удобноное приложение...из минусов хотя...  2017-08-14\n",
       "2       5                                        Отлично все  2017-08-14\n",
       "3       5  Стал зависать на 1% работы антивируса. Дальше ...  2017-08-14\n",
       "4       5                     Очень удобно, работает быстро.  2017-08-14"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_excel('../data/отзывы за лето.xls')\n",
    "print(f'Shape:\\n{data_df.shape}\\n'\n",
    "      f'Describe:\\n{data_df.describe().T}\\n'\n",
    "      f'Column name:\\n{data_df.columns}\\n')\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19eebe96-09c4-4603-9e15-cd40bd7df164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Rating</th>\n",
       "      <td>20659.0</td>\n",
       "      <td>4.259015</td>\n",
       "      <td>1.348884</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count      mean       std  min  25%  50%  75%  max\n",
       "Rating  20659.0  4.259015  1.348884  1.0  4.0  5.0  5.0  5.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cf2923-a5a2-4ae0-ba57-f14cf4e1e61e",
   "metadata": {},
   "source": [
    "### Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6a72005-5bef-4562-a362-8f15d111b1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install stop-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61345b4d-a7a1-455f-9bae-33b35cace4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from stop_words import get_stop_words\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6216689e-38e8-4406-bd1c-728e784404fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_ru = set(get_stop_words(\"ru\"))\n",
    "sw_en = set(get_stop_words(\"en\"))\n",
    "exclude = set(punctuation)\n",
    "morpher = MorphAnalyzer()\n",
    "\n",
    "def preprocess_text(txt):\n",
    "    txt = str(txt)\n",
    "    txt = \"\".join(c for c in txt if c not in exclude)\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(\"\\sне\", \"не\", txt)\n",
    "    txt = [morpher.parse(word)[0].normal_form for word in txt.split() if word not in sw_ru or sw_en]\n",
    "    return \" \".join(txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be1d6291-e1f4-43d8-b4f5-c5d9f148e67d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Content</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>it just works</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>в целое удобноной приложениеиз минус хотеть сл...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>отлично всё</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating                                            Content        Date\n",
       "0       5                                      it just works  2017-08-14\n",
       "1       4  в целое удобноной приложениеиз минус хотеть сл...  2017-08-14\n",
       "2       5                                        отлично всё  2017-08-14"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['Content'] = data_df['Content'].apply(preprocess_text)\n",
    "data_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6b22c9-6223-48d7-991b-89cefdae5df0",
   "metadata": {},
   "source": [
    "#### Разделение выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d679f93-d305-4cd0-809b-454055a96876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_df shape:\t(20659, 3)\n",
      "train_dfshape:\t(16527, 3)\n",
      "test_df shape:\t(4132, 3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(data_df, test_size=0.2, random_state=21,)\n",
    "print(f'data_df shape:\\t{data_df.shape}\\n'\n",
    "      f'train_dfshape:\\t{df_train.shape}\\n'\n",
    "      f'test_df shape:\\t{df_test.shape}\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0921e20-4e82-42b1-b3d5-dc408d5ff19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = \" \".join(df_train['Content'])\n",
    "train_corpus = train_corpus.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6956f261-971d-4b85-b684-2e76ee1fa13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/oleg_rev/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "tokens = word_tokenize(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0a13645-d94d-4049-a890-7e304190fffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 200\n",
    "max_len = 40\n",
    "num_classes = 1\n",
    "\n",
    "# Training\n",
    "epochs = 20\n",
    "batch_size = 512\n",
    "print_batch_n = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6376a233-8f7f-4a93-947d-f8d31605cb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_filtered = [word for word in tokens if word.isalnum()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b57ec8fb-7d7f-42cb-826d-c4213627373e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "dist = FreqDist(tokens_filtered)\n",
    "tokens_filtered_top = [pair[0] for pair in dist.most_common(max_words-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5107178f-25a2-44a4-907f-28b8873e671c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['приложение', 'всё', 'и', 'очень', 'удобно', 'в', 'я', 'на', 'работать', 'с']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_filtered_top[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e6e198d-654b-490c-9fc7-61d6832ac6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = {v: k for k, v in dict(enumerate(tokens_filtered_top, 1)).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4423d03b-9128-44f9-a038-f416140e6a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_sequence(text, maxlen):\n",
    "    result = []\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens_filtered = [word for word in tokens if word.isalnum()]\n",
    "    for word in tokens_filtered:\n",
    "        if word in vocabulary:\n",
    "            result.append(vocabulary[word])\n",
    "    padding = [0]*(maxlen-len(result))\n",
    "    return padding + result[-maxlen:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2827a197-39e1-44b0-9377-fef17cadcc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.asarray([text_to_sequence(text, max_len) for text in df_train['Content']], dtype=np.int32)\n",
    "x_test = np.asarray([text_to_sequence(text, max_len) for text in df_test['Content']], dtype=np.int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "746f5d60-a6a0-472e-af12-67e234f187ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16527, 40)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1b59428-b95d-4373-85f3-1fd713c8ddcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4132, 40)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85ad42d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Выполнение заданий"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8f0954",
   "metadata": {},
   "source": [
    "<p><a name=\"task_1\"></a></p>\n",
    "\n",
    "## 1. Учим conv сеть для классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d9c04ab4-14a4-4e91-a597-59d8c36d8567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Rating'].max()\n",
    "type(df_train[\"class\"].unique()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "55ea9dd2-4aff-43aa-b8ae-7be47d786750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16527,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Rating'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a0db2a19-86fb-42eb-8949-56b0b497e423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 4, 1, 2, 3])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"Rating\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "08a60b30-2eba-4cc5-9a49-614b79b404ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=6\n",
    "y_train = keras.utils.to_categorical(df_train['Rating'], num_classes)\n",
    "y_test = keras.utils.to_categorical(df_test['Rating'], num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b2abf043-4574-4c24-b9b7-f58d63d904d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-26 00:48:39.804273: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-09-26 00:48:39.804943: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-26 00:48:39.808297: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_len))\n",
    "model.add(Conv1D(128, 3))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(10))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "44e68162-50cf-4dcc-b9e3-e7e8dae63435",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a5de45ce-271c-42ba-a955-658f9f259d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-26 00:48:44.592118: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
      "2021-09-26 00:48:44.592191: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
      "2021-09-26 00:48:44.592771: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
      "2021-09-26 00:48:44.664291: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-09-26 00:48:44.682768: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2595000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 2/30 [=>............................] - ETA: 5s - loss: 1.7903 - accuracy: 0.1343     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-26 00:48:45.593447: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
      "2021-09-26 00:48:45.593490: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 6s 181ms/step - loss: 1.5097 - accuracy: 0.5983 - val_loss: 1.0473 - val_accuracy: 0.7187\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 5s 167ms/step - loss: 1.0237 - accuracy: 0.7134 - val_loss: 0.8190 - val_accuracy: 0.7665\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 5s 172ms/step - loss: 0.8498 - accuracy: 0.7522 - val_loss: 0.7529 - val_accuracy: 0.7719\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 5s 177ms/step - loss: 0.7947 - accuracy: 0.7618 - val_loss: 0.7266 - val_accuracy: 0.7737\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 5s 173ms/step - loss: 0.7502 - accuracy: 0.7697 - val_loss: 0.7083 - val_accuracy: 0.7762\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 5s 173ms/step - loss: 0.7365 - accuracy: 0.7686 - val_loss: 0.6932 - val_accuracy: 0.7792\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 5s 167ms/step - loss: 0.7169 - accuracy: 0.7751 - val_loss: 0.6819 - val_accuracy: 0.7804\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 5s 167ms/step - loss: 0.7146 - accuracy: 0.7708 - val_loss: 0.6714 - val_accuracy: 0.7804\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 5s 163ms/step - loss: 0.6739 - accuracy: 0.7810 - val_loss: 0.6621 - val_accuracy: 0.7816\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 5s 172ms/step - loss: 0.6740 - accuracy: 0.7779 - val_loss: 0.6541 - val_accuracy: 0.7828\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 5s 164ms/step - loss: 0.6719 - accuracy: 0.7758 - val_loss: 0.6492 - val_accuracy: 0.7846\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 5s 174ms/step - loss: 0.6317 - accuracy: 0.7889 - val_loss: 0.6419 - val_accuracy: 0.7840\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 5s 165ms/step - loss: 0.6363 - accuracy: 0.7820 - val_loss: 0.6369 - val_accuracy: 0.7871\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 5s 158ms/step - loss: 0.6366 - accuracy: 0.7814 - val_loss: 0.6344 - val_accuracy: 0.7864\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 5s 160ms/step - loss: 0.6157 - accuracy: 0.7886 - val_loss: 0.6312 - val_accuracy: 0.7871\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 5s 162ms/step - loss: 0.6129 - accuracy: 0.7840 - val_loss: 0.6333 - val_accuracy: 0.7846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-26 00:48:45.766377: I tensorflow/core/profiler/lib/profiler_session.cc:71] Profiler session collecting data.\n",
      "2021-09-26 00:48:45.770635: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
      "2021-09-26 00:48:45.775752: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: ./logs/train/plugins/profile/2021_09_26_00_48_45\n",
      "2021-09-26 00:48:45.778283: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for trace.json.gz to ./logs/train/plugins/profile/2021_09_26_00_48_45/localhost.localdomain.trace.json.gz\n",
      "2021-09-26 00:48:45.792402: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: ./logs/train/plugins/profile/2021_09_26_00_48_45\n",
      "2021-09-26 00:48:45.793175: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for memory_profile.json.gz to ./logs/train/plugins/profile/2021_09_26_00_48_45/localhost.localdomain.memory_profile.json.gz\n",
      "2021-09-26 00:48:45.795423: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: ./logs/train/plugins/profile/2021_09_26_00_48_45Dumped tool data for xplane.pb to ./logs/train/plugins/profile/2021_09_26_00_48_45/localhost.localdomain.xplane.pb\n",
      "Dumped tool data for overview_page.pb to ./logs/train/plugins/profile/2021_09_26_00_48_45/localhost.localdomain.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to ./logs/train/plugins/profile/2021_09_26_00_48_45/localhost.localdomain.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to ./logs/train/plugins/profile/2021_09_26_00_48_45/localhost.localdomain.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to ./logs/train/plugins/profile/2021_09_26_00_48_45/localhost.localdomain.kernel_stats.pb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tensorboard=TensorBoard(log_dir='./logs', write_graph=True, write_images=True)\n",
    "early_stopping=EarlyStopping(monitor='val_loss')  \n",
    "\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[tensorboard, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b439ba04-69a5-484e-9c88-8934900a4426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 66ms/step - loss: 0.6906 - accuracy: 0.7655\n",
      "\n",
      "\n",
      "Test score: 0.6905776262283325\n",
      "Test accuracy: 0.765488862991333\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "af6a1c6b-2d42-457e-a45c-8543de6919ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 61ms/step\n"
     ]
    }
   ],
   "source": [
    "results = model.predict(x_test, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d783afec",
   "metadata": {},
   "source": [
    "<p><a name=\"task_2\"></a></p>\n",
    "\n",
    "## 2. Рассмотреть 2-а варианта сеточек\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40156fa2-75b9-4ce7-8f0a-15262ec68d45",
   "metadata": {},
   "source": [
    "<p><a name=\"task_2.1\"></a></p>\n",
    "\n",
    "### 2.1. Инициализировать tf.keras.layers.Embedding предобученными векторами взять к примеру с https://rusvectores.org/ru/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3597a17-5738-4f00-984c-57bff6eb6f79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d17f8a6-b4ea-4398-8f16-eb6509e07040",
   "metadata": {},
   "source": [
    "<p><a name=\"task_2.2\"></a></p>\n",
    "\n",
    "### 2.2. Инициализировать слой tf.keras.layers.Embedding по умолчанию (ну то есть вам ничего не делать с весами)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977fb8a6-08dc-41f6-aecf-7971fd529bb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2be222fb",
   "metadata": {},
   "source": [
    "<p><a name=\"task_3\"></a></p>\n",
    "\n",
    "## 3. Сравнить две архитектуры с предобученными весами и когда tf.keras.layers.Embedding обучается сразу со всей сеточкой, что получилось лучше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fb00fb-b322-471f-8b26-8634db06f77b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
